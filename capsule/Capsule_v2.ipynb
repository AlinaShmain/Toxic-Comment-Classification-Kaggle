{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
      "\u001b[K    100% |████████████████████████████████| 337kB 2.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already up-to-date: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
      "Collecting numpy>=1.9.1 (from keras)\n",
      "  Downloading numpy-1.14.2-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.2MB 122kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.9.0 (from keras)\n",
      "  Using cached six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from keras)\n",
      "Installing collected packages: numpy, six, pyyaml, keras\n",
      "  Found existing installation: numpy 1.14.0\n",
      "    Uninstalling numpy-1.14.0:\n",
      "      Successfully uninstalled numpy-1.14.0\n",
      "  Found existing installation: six 1.10.0\n",
      "    Uninstalling six-1.10.0:\n",
      "      Successfully uninstalled six-1.10.0\n",
      "  Found existing installation: PyYAML 3.11\n",
      "    Uninstalling PyYAML-3.11:\n",
      "      Successfully uninstalled PyYAML-3.11\n",
      "  Found existing installation: Keras 2.0.6\n",
      "    Uninstalling Keras-2.0.6:\n",
      "      Successfully uninstalled Keras-2.0.6\n",
      "Successfully installed keras-2.1.5 numpy-1.14.2 pyyaml-3.12 six-1.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "EMBEDDING_FILE='/public/models/glove/glove.840B.300d.txt'\n",
    "TRAIN_DATA_FILE='/public/toxic_comments/train.csv'\n",
    "TEST_DATA_FILE='/public/toxic_comments/test.csv'\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "MAX_NB_WORDS = 100000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "num_lstm = 300\n",
    "num_dense = 256\n",
    "rate_drop_lstm = 0.2\n",
    "rate_drop_dense = 0.2\n",
    "\n",
    "act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(text, stemming = False, lemmatize=False):    \n",
    "    text = text.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+\\-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in text.split()])\n",
    "    if lemmatize:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w) for w in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors\n",
      "Found 2195895 word vectors of glove.\n",
      "-0.01444638 0.47249147\n",
      "Total 2195895 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Indexing word vectors')\n",
    "\n",
    "count = 0\n",
    "embeddings_index = {}\n",
    "f = open(EMBEDDING_FILE)\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = ' '.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    embeddings_index[word] = coefs.reshape(-1)\n",
    "    coef = embeddings_index[word]\n",
    "f.close()\n",
    "\n",
    "print('Found %d word vectors of glove.' % len(embeddings_index))\n",
    "emb_mean,emb_std = coef.mean(), coef.std()\n",
    "print(emb_mean,emb_std)\n",
    "\n",
    "print('Total %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test_df = pd.read_csv(TEST_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras.layers import concatenate, CuDNNGRU\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Found 292462 unique tokens\n",
      "Shape of data tensor: (159571, 150)\n",
      "Shape of label tensor: (159571, 6)\n",
      "Shape of test_data tensor: (153164, 150)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "print('Processing text dataset')\n",
    "\n",
    "train_df['comment_text'] = train_df['comment_text'].map(lambda x: cleanData(x,  stemming = False, \n",
    "                                                                            lemmatize=False))\n",
    "test_df['comment_text'] = test_df['comment_text'].map(lambda x: cleanData(x,  stemming = False, \n",
    "                                                                          lemmatize=False))\n",
    "\n",
    "#Regex to remove all Non-Alpha Numeric and space\n",
    "special_character_removal=re.compile(r'[^a-z\\d ]',re.IGNORECASE)\n",
    "#regex to replace all numerics\n",
    "replace_numbers=re.compile(r'\\d+',re.IGNORECASE)\n",
    "\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    #Remove Special Characters\n",
    "    text=special_character_removal.sub('',text)\n",
    "    #Replace Numbers\n",
    "    text=replace_numbers.sub('n',text)\n",
    "\n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return(text)\n",
    "\n",
    "\n",
    "list_sentences_train = train_df[\"comment_text\"].fillna(\"NA\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train_df[list_classes].values\n",
    "list_sentences_test = test_df[\"comment_text\"].fillna(\"NA\").values\n",
    "\n",
    "\n",
    "comments = []\n",
    "for text in list_sentences_train:\n",
    "    comments.append(text_to_wordlist(text))\n",
    "    \n",
    "test_comments=[]\n",
    "for text in list_sentences_test:\n",
    "    test_comments.append(text_to_wordlist(text))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(comments + test_comments)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(comments)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_comments)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', y.shape)\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of test_data tensor:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (159571, 150)\n",
      "Shape of label tensor: (159571, 6)\n",
      "Shape of test_data tensor: (153164, 150)\n"
     ]
    }
   ],
   "source": [
    "data_post = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH,padding='post', truncating='post')\n",
    "print('Shape of data tensor:', data_post.shape)\n",
    "print('Shape of label tensor:', y.shape)\n",
    "\n",
    "test_data_post = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "print('Shape of test_data tensor:', test_data_post.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix\n",
      "Null word embeddings: 21603\n"
     ]
    }
   ],
   "source": [
    "print('Preparing embedding matrix')\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=100000\n",
    "maxlen=150\n",
    "embed_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import K, Activation\n",
    "from keras.engine import Layer\n",
    "from keras.layers import Dense, Input, Embedding, Dropout, Bidirectional, GRU, Flatten, SpatialDropout1D\n",
    "gru_len = 128\n",
    "Routings = 5\n",
    "Num_capsule = 10\n",
    "Dim_capsule = 16\n",
    "dropout_p = 0.25\n",
    "rate_drop_dense = 0.28\n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    # s_squared_norm is really small\n",
    "    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n",
    "    # return scale * x\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "\n",
    "# A Capsule Implement with Pure Keras\n",
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input1_pre = Input(shape=(maxlen,))\n",
    "    embed_layer1_pre = Embedding(max_features,\n",
    "                            embed_size,\n",
    "                            input_length=maxlen,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)(input1_pre)\n",
    "    embed_layer1_pre = SpatialDropout1D(0.4)(embed_layer1_pre)\n",
    "    \n",
    "    x_pre = Bidirectional(CuDNNGRU(128, return_sequences=True))(embed_layer1_pre)\n",
    "    capsule_pre = Capsule(num_capsule=10, dim_capsule=16, routings=5,share_weights=True)(x_pre)\n",
    "    # output_capsule = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)))(capsule)\n",
    "    capsule_pre = GlobalMaxPooling1D()(capsule_pre)\n",
    "    capsule_pre = Dropout(0.25)(capsule_pre)\n",
    "    \n",
    "    input1_post = Input(shape=(maxlen,))\n",
    "    embed_layer1_post = Embedding(max_features,\n",
    "                            embed_size,\n",
    "                            input_length=maxlen,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)(input1_post)\n",
    "    embed_layer1_post = SpatialDropout1D(0.4)(embed_layer1_post)\n",
    "    \n",
    "    x_post = Bidirectional(CuDNNGRU(128, return_sequences=True))(embed_layer1_post)\n",
    "    capsule_post = Capsule(num_capsule=10, dim_capsule=16, routings=5,share_weights=True)(x_post)\n",
    "    #  output_capsule = Lambda(lambda x: K.sqrt(K.sum(K.square(x), 2)))(capsule)\n",
    "    capsule_post = GlobalMaxPooling1D()(capsule_post)\n",
    "    capsule_post = Dropout(0.25)(capsule_post)\n",
    "    \n",
    "    concat = concatenate([capsule_pre,capsule_post])\n",
    "    output = Dense(6, activation='sigmoid')(concat)\n",
    "    \n",
    "    model = Model(inputs=[input1_pre,input1_post], outputs=output)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(lr=1e-3,decay=0),\n",
    "        metrics=['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "\n",
    "test_predicts_list = []\n",
    "\n",
    "def train_folds(data,data_post, y,fold_count=10):\n",
    "    print(\"Starting to train models...\")\n",
    "    fold_size = len(data) // fold_count\n",
    "    models = []\n",
    "    for fold_id in range(0, fold_count):\n",
    "        fold_start = fold_size * fold_id\n",
    "        fold_end = fold_start + fold_size\n",
    "\n",
    "        if fold_id == fold_size - 1:\n",
    "            fold_end = len(data)\n",
    "\n",
    "        print(\"Fold {0}\".format(fold_id))\n",
    "        \n",
    "        train_x = np.concatenate([data[:fold_start], data[fold_end:]])\n",
    "        train_xp = np.concatenate([data_post[:fold_start], data_post[fold_end:]])\n",
    "        train_y = np.concatenate([y[:fold_start], y[fold_end:]])\n",
    "\n",
    "        val_x = data[fold_start:fold_end]\n",
    "        val_xp = data_post[fold_start:fold_end]\n",
    "        val_y = y[fold_start:fold_end]\n",
    "        \n",
    "        file_path=\"capsule_fold{0}.h5\".format(fold_id)\n",
    "        model = get_model()\n",
    "        checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
    "        RocAuc = RocAucEvaluation(validation_data=([val_x, val_xp], val_y), interval=1)\n",
    "        callbacks_list = [checkpoint, early,RocAuc] \n",
    "\n",
    "        hist = model.fit([train_x, train_xp], train_y, epochs=15, batch_size=128, shuffle=True, \n",
    "                         validation_data=([val_x, val_xp], val_y), callbacks = callbacks_list, verbose=1)\n",
    "        model.load_weights(file_path)\n",
    "        best_score = min(hist.history['val_loss'])\n",
    "        \n",
    "        print(\"Fold {0} loss {1}\".format(fold_id, best_score))\n",
    "        print(\"Predicting validation...\")\n",
    "        val_predicts_path = \"capsule_val_predicts{0}.npy\".format(fold_id)\n",
    "        val_predicts = model.predict([val_x, val_xp], batch_size=1024, verbose=1)\n",
    "        np.save(val_predicts_path, val_predicts)\n",
    "        \n",
    "        print(\"Predicting results...\")\n",
    "        test_predicts_path = \"capsule_test_predicts{0}.npy\".format(fold_id)\n",
    "        test_predicts = model.predict([test_data, test_data_post], batch_size=1024, verbose=1)\n",
    "        test_predicts_list.append(test_predicts)\n",
    "        np.save(test_predicts_path, test_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train models...\n",
      "Fold 0\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.1001 - acc: 0.9751 - val_loss: 0.0490 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04905, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.977384\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0511 - acc: 0.9819 - val_loss: 0.0449 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04905 to 0.04492, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.983373\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0462 - acc: 0.9829 - val_loss: 0.0430 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04492 to 0.04298, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.982130\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0438 - acc: 0.9835 - val_loss: 0.0412 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04298 to 0.04123, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.985777\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0417 - acc: 0.9841 - val_loss: 0.0408 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04123 to 0.04076, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.986720\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0402 - acc: 0.9845 - val_loss: 0.0400 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04076 to 0.03996, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.987886\n",
      "Epoch 7/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0384 - acc: 0.9850 - val_loss: 0.0398 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03996 to 0.03980, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.988263\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0373 - acc: 0.9855 - val_loss: 0.0401 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.988065\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0364 - acc: 0.9857 - val_loss: 0.0389 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03980 to 0.03889, saving model to capsule_fold0.h5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.988940\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0351 - acc: 0.9862 - val_loss: 0.0394 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.988177\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0345 - acc: 0.9864 - val_loss: 0.0405 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.987542\n",
      "Epoch 12/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0339 - acc: 0.9865 - val_loss: 0.0402 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.987846\n",
      "Fold 0 loss 0.0388865549664319\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 266us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 39s 251us/step\n",
      "Fold 1\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0972 - acc: 0.9744 - val_loss: 0.0526 - val_acc: 0.9807\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05257, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.977137\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0515 - acc: 0.9817 - val_loss: 0.0465 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05257 to 0.04654, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.981724\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0474 - acc: 0.9826 - val_loss: 0.0449 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04654 to 0.04485, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.983403\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0442 - acc: 0.9833 - val_loss: 0.0425 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04485 to 0.04247, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.985397\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0422 - acc: 0.9839 - val_loss: 0.0444 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.985572\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0413 - acc: 0.9841 - val_loss: 0.0416 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04247 to 0.04158, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.987872\n",
      "Epoch 7/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0396 - acc: 0.9846 - val_loss: 0.0410 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04158 to 0.04105, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.988720\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0383 - acc: 0.9850 - val_loss: 0.0407 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04105 to 0.04071, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.989314\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0369 - acc: 0.9854 - val_loss: 0.0403 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04071 to 0.04035, saving model to capsule_fold1.h5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.989409\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0360 - acc: 0.9858 - val_loss: 0.0409 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.988949\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0354 - acc: 0.9860 - val_loss: 0.0407 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.989225\n",
      "Epoch 12/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0343 - acc: 0.9863 - val_loss: 0.0408 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.989253\n",
      "Fold 1 loss 0.04034954370326018\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 259us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 39s 252us/step\n",
      "Fold 2\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0814 - acc: 0.9768 - val_loss: 0.0482 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04822, saving model to capsule_fold2.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.980445\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0509 - acc: 0.9816 - val_loss: 0.0453 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04822 to 0.04534, saving model to capsule_fold2.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.983531\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0458 - acc: 0.9829 - val_loss: 0.0423 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04534 to 0.04235, saving model to capsule_fold2.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986234\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0434 - acc: 0.9836 - val_loss: 0.0406 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04235 to 0.04058, saving model to capsule_fold2.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.989089\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0419 - acc: 0.9839 - val_loss: 0.0395 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04058 to 0.03948, saving model to capsule_fold2.h5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.989518\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0406 - acc: 0.9844 - val_loss: 0.0398 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.990396\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0399 - acc: 0.9846 - val_loss: 0.0394 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03948 to 0.03944, saving model to capsule_fold2.h5\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.990547\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0381 - acc: 0.9852 - val_loss: 0.0389 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03944 to 0.03890, saving model to capsule_fold2.h5\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.991079\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0370 - acc: 0.9855 - val_loss: 0.0395 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.991103\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0360 - acc: 0.9858 - val_loss: 0.0392 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.990921\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0354 - acc: 0.9861 - val_loss: 0.0390 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.990842\n",
      "Fold 2 loss 0.03889602224765142\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 260us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 38s 251us/step\n",
      "Fold 3\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0878 - acc: 0.9773 - val_loss: 0.0502 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05021, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.958450\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0509 - acc: 0.9818 - val_loss: 0.0458 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05021 to 0.04585, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.978881\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0465 - acc: 0.9829 - val_loss: 0.0440 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04585 to 0.04396, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.981615\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0439 - acc: 0.9833 - val_loss: 0.0430 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04396 to 0.04303, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.980778\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 208s 1ms/step - loss: 0.0421 - acc: 0.9839 - val_loss: 0.0421 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04303 to 0.04206, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.984318\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0404 - acc: 0.9843 - val_loss: 0.0414 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04206 to 0.04135, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.984366\n",
      "Epoch 7/15\n",
      "143614/143614 [==============================] - 209s 1ms/step - loss: 0.0389 - acc: 0.9848 - val_loss: 0.0408 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04135 to 0.04076, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.985165\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0377 - acc: 0.9851 - val_loss: 0.0408 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.986565\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0363 - acc: 0.9856 - val_loss: 0.0404 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04076 to 0.04040, saving model to capsule_fold3.h5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.986910\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0353 - acc: 0.9861 - val_loss: 0.0412 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.986440\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0414 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.986348\n",
      "Epoch 12/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0335 - acc: 0.9866 - val_loss: 0.0413 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.987019\n",
      "Fold 3 loss 0.04040009998372939\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 264us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 39s 252us/step\n",
      "Fold 4\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 213s 1ms/step - loss: 0.0857 - acc: 0.9769 - val_loss: 0.0487 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04871, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.979585\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0523 - acc: 0.9813 - val_loss: 0.0448 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04871 to 0.04477, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.982103\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0482 - acc: 0.9823 - val_loss: 0.0425 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04477 to 0.04250, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.984988\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0450 - acc: 0.9831 - val_loss: 0.0414 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04250 to 0.04135, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.985288\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0429 - acc: 0.9836 - val_loss: 0.0400 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04135 to 0.04001, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.986842\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0412 - acc: 0.9841 - val_loss: 0.0393 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04001 to 0.03933, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.988585\n",
      "Epoch 7/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0400 - acc: 0.9846 - val_loss: 0.0391 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03933 to 0.03910, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.988919\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0386 - acc: 0.9849 - val_loss: 0.0388 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03910 to 0.03880, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.987861\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0374 - acc: 0.9853 - val_loss: 0.0390 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.989269\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0367 - acc: 0.9855 - val_loss: 0.0412 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.986287\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0369 - acc: 0.9855 - val_loss: 0.0387 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03880 to 0.03870, saving model to capsule_fold4.h5\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.989927\n",
      "Epoch 12/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0355 - acc: 0.9860 - val_loss: 0.0388 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.989726\n",
      "Epoch 13/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0397 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.989605\n",
      "Epoch 14/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0334 - acc: 0.9866 - val_loss: 0.0395 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ROC-AUC - epoch: 14 - score: 0.990172\n",
      "Fold 4 loss 0.03870266953554079\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 263us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 39s 252us/step\n",
      "Fold 5\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 213s 1ms/step - loss: 0.0884 - acc: 0.9772 - val_loss: 0.0472 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04715, saving model to capsule_fold5.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.975727\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0498 - acc: 0.9821 - val_loss: 0.0426 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04715 to 0.04264, saving model to capsule_fold5.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.983071\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0475 - acc: 0.9824 - val_loss: 0.0425 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04264 to 0.04252, saving model to capsule_fold5.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.983015\n",
      "Epoch 4/15\n",
      " 31104/143614 [=====>........................] - ETA: 2:39 - loss: 0.0443 - acc: 0.9835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0370 - acc: 0.9855 - val_loss: 0.0386 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.988935\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0361 - acc: 0.9858 - val_loss: 0.0383 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03829 to 0.03826, saving model to capsule_fold5.h5\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.988859\n",
      "Epoch 11/15\n",
      "126336/143614 [=========================>....] - ETA: 24s - loss: 0.0349 - acc: 0.9863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0467 - acc: 0.9827 - val_loss: 0.0421 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04421 to 0.04215, saving model to capsule_fold6.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.985340\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0438 - acc: 0.9832 - val_loss: 0.0407 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04215 to 0.04072, saving model to capsule_fold6.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.985515\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0423 - acc: 0.9838 - val_loss: 0.0397 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04072 to 0.03971, saving model to capsule_fold6.h5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.987021\n",
      "Epoch 6/15\n",
      " 47232/143614 [========>.....................] - ETA: 2:15 - loss: 0.0411 - acc: 0.9840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0509 - acc: 0.9819 - val_loss: 0.0453 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04908 to 0.04534, saving model to capsule_fold7.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.982731\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0466 - acc: 0.9828 - val_loss: 0.0426 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04534 to 0.04258, saving model to capsule_fold7.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.984120\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0435 - acc: 0.9837 - val_loss: 0.0416 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04258 to 0.04156, saving model to capsule_fold7.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.985784\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0414 - acc: 0.9842 - val_loss: 0.0420 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.986349\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0400 - acc: 0.9845 - val_loss: 0.0404 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04156 to 0.04037, saving model to capsule_fold7.h5\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.986280\n",
      "Epoch 7/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0387 - acc: 0.9850 - val_loss: 0.0404 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.987149\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0375 - acc: 0.9854 - val_loss: 0.0405 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.986624\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0363 - acc: 0.9858 - val_loss: 0.0404 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04037 to 0.04036, saving model to capsule_fold7.h5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.986269\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0352 - acc: 0.9862 - val_loss: 0.0407 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.986057\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0342 - acc: 0.9865 - val_loss: 0.0409 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.986725\n",
      "Epoch 12/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0335 - acc: 0.9868 - val_loss: 0.0409 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.986623\n",
      "Fold 7 loss 0.0403625494182136\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 266us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 39s 253us/step\n",
      "Fold 8\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0809 - acc: 0.9779 - val_loss: 0.0484 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04837, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.974320\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0495 - acc: 0.9821 - val_loss: 0.0419 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04837 to 0.04193, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.985422\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0454 - acc: 0.9830 - val_loss: 0.0405 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04193 to 0.04046, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986879\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0430 - acc: 0.9837 - val_loss: 0.0404 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04046 to 0.04038, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.987640\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0412 - acc: 0.9841 - val_loss: 0.0394 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04038 to 0.03941, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.987470\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0397 - acc: 0.9845 - val_loss: 0.0390 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03941 to 0.03898, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.987784\n",
      "Epoch 7/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0384 - acc: 0.9850 - val_loss: 0.0391 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.988111\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0409 - acc: 0.9840 - val_loss: 0.0405 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.987265\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0398 - acc: 0.9844 - val_loss: 0.0388 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03898 to 0.03884, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.988311\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0378 - acc: 0.9851 - val_loss: 0.0389 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.988116\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0369 - acc: 0.9854 - val_loss: 0.0386 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03884 to 0.03857, saving model to capsule_fold8.h5\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.988984\n",
      "Epoch 12/15\n",
      "143614/143614 [==============================] - 210s 1ms/step - loss: 0.0357 - acc: 0.9858 - val_loss: 0.0408 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.988917\n",
      "Epoch 13/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0348 - acc: 0.9862 - val_loss: 0.0388 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.989312\n",
      "Epoch 14/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0341 - acc: 0.9864 - val_loss: 0.0390 - val_acc: 0.9851\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 14 - score: 0.989030\n",
      "Fold 8 loss 0.03856543695347877\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 263us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 39s 252us/step\n",
      "Fold 9\n",
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/15\n",
      "143614/143614 [==============================] - 214s 1ms/step - loss: 0.0823 - acc: 0.9770 - val_loss: 0.0512 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05121, saving model to capsule_fold9.h5\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.973454\n",
      "Epoch 2/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0516 - acc: 0.9814 - val_loss: 0.0469 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05121 to 0.04691, saving model to capsule_fold9.h5\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.978050\n",
      "Epoch 3/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0473 - acc: 0.9824 - val_loss: 0.0449 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04691 to 0.04490, saving model to capsule_fold9.h5\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.981289\n",
      "Epoch 4/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0449 - acc: 0.9831 - val_loss: 0.0432 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04490 to 0.04319, saving model to capsule_fold9.h5\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.983820\n",
      "Epoch 5/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0427 - acc: 0.9837 - val_loss: 0.0427 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04319 to 0.04266, saving model to capsule_fold9.h5\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.985937\n",
      "Epoch 6/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0418 - acc: 0.9838 - val_loss: 0.0419 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04266 to 0.04188, saving model to capsule_fold9.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.987210\n",
      "Epoch 7/15\n",
      "143614/143614 [==============================] - 211s 1ms/step - loss: 0.0401 - acc: 0.9845 - val_loss: 0.0419 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.988784\n",
      "Epoch 8/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0388 - acc: 0.9849 - val_loss: 0.0402 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04188 to 0.04024, saving model to capsule_fold9.h5\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.989455\n",
      "Epoch 9/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0374 - acc: 0.9853 - val_loss: 0.0402 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04024 to 0.04020, saving model to capsule_fold9.h5\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.988745\n",
      "Epoch 10/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0365 - acc: 0.9857 - val_loss: 0.0405 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.989526\n",
      "Epoch 11/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0355 - acc: 0.9861 - val_loss: 0.0405 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.989414\n",
      "Epoch 12/15\n",
      "143614/143614 [==============================] - 212s 1ms/step - loss: 0.0347 - acc: 0.9863 - val_loss: 0.0416 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.988936\n",
      "Fold 9 loss 0.04019576376549745\n",
      "Predicting validation...\n",
      "15957/15957 [==============================] - 4s 262us/step\n",
      "Predicting results...\n",
      "153164/153164 [==============================] - 39s 253us/step\n"
     ]
    }
   ],
   "source": [
    "train_folds(data, data_post, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "CLASSES = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "print(len(test_predicts_list))\n",
    "test_predicts_am = np.zeros(test_predicts_list[0].shape)\n",
    "\n",
    "for fold_predict in test_predicts_list:\n",
    "    test_predicts_am += fold_predict\n",
    "\n",
    "test_predicts_am = (test_predicts_am / len(test_predicts_list))\n",
    "\n",
    "test_ids = test_df[\"id\"].values\n",
    "test_ids = test_ids.reshape((len(test_ids), 1))\n",
    "\n",
    "test_predicts_am = pd.DataFrame(data=test_predicts_am, columns=CLASSES)\n",
    "test_predicts_am[\"id\"] = test_ids\n",
    "test_predicts_am = test_predicts_am[[\"id\"] + CLASSES]\n",
    "test_predicts_am.to_csv(\"10fold_capsule_am.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicts = np.ones(test_predicts_list[0].shape)\n",
    "\n",
    "for fold_predict in test_predicts_list:\n",
    "    test_predicts *= fold_predict\n",
    "\n",
    "test_predicts **= (1. / len(test_predicts_list))\n",
    "\n",
    "test_ids = test_df[\"id\"].values\n",
    "test_ids = test_ids.reshape((len(test_ids), 1))\n",
    "\n",
    "test_predicts = pd.DataFrame(data=test_predicts, columns=CLASSES)\n",
    "test_predicts[\"id\"] = test_ids\n",
    "test_predicts = test_predicts[[\"id\"] + CLASSES]\n",
    "test_predicts.to_csv(\"10fold_capsule_gm.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
